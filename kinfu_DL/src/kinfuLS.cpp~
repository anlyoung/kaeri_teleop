/*
* Software License Agreement (BSD License)
*
* Point Cloud Library (PCL) - www.pointclouds.org
* Copyright (c) 2011, Willow Garage, Inc.
*
* All rights reserved.
*
* Redistribution and use in source and binary forms, with or without
* modification, are permitted provided that the following conditions
* are met:
*
* * Redistributions of source code must retain the above copyright
* notice, this list of conditions and the following disclaimer.
* * Redistributions in binary form must reproduce the above
* copyright notice, this list of conditions and the following
* disclaimer in the documentation and/or other materials provided
* with the distribution.
* * Neither the name of Willow Garage, Inc. nor the names of its
* contributors may be used to endorse or promote products derived
* from this software without specific prior written permission.
*
* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
* "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
* LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
* FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
* COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
* INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
* BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
* LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
* CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
* LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
* ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
* POSSIBILITY OF SUCH DAMAGE.
*
*/
/*
* Based on the KinfuLS ROS wrapper by Michael Korn <michael.korn(at)uni-due.de>
* http://fsstud.is.uni-due.de/svn/ros/is/kinfu/
*/
/*
* Modified by Riccardo Monica 
*   RIMLab, Department of Information Engineering, University of Parma, Italy
*   http://www.rimlab.ce.unipr.it/
* 2013-2015
*/
// Linux
#include <unistd.h>

// STL
#include <iostream>
#include <vector>
#include <list>
#include <deque>

// Boost
#include <boost/filesystem.hpp>
#include <boost/thread/mutex.hpp>
#include <boost/thread/thread.hpp>

// PCL
#include <pcl/console/parse.h>
#include <pcl/common/time.h>
#include <pcl/point_cloud.h>
#include <pcl/point_types.h>
#include <pcl/visualization/pcl_visualizer.h>
#include <pcl/common/angles.h>

// PCL/GPU
#include <pcl/gpu/kinfu_large_scale/kinfu.h>
#include <pcl/gpu/kinfu_large_scale/marching_cubes.h>
#include <pcl/gpu/containers/initialization.h>
#include <pcl/gpu/kinfu_large_scale/screenshot_manager.h>

// ROS
#include <image_transport/image_transport.h>
#include <image_transport/camera_subscriber.h>
#include <tf/transform_broadcaster.h>
#include <tf/transform_listener.h>
#include <sensor_msgs/fill_image.h>
#include <std_msgs/Empty.h>
#include <ros/spinner.h>

#include <message_filters/subscriber.h>
#include <message_filters/synchronizer.h>
#include <message_filters/sync_policies/approximate_time.h>
#include <message_filters/time_synchronizer.h>
#include <sensor_msgs/Image.h>
#include <sensor_msgs/CameraInfo.h>

#include <std_msgs/Bool.h>
#include <geometry_msgs/Pose.h>
#include <geometry_msgs/Point.h>
#include <visualization_msgs/Marker.h>


// Custom
#include "parameters.h"
#include "worlddownloadmanager.h"
#include "commandsubscriber.h"
#include "weightcubelistener.h"
#include "incompletepointslistener.h"

// ROS custom messages
#include <kinfu_msgs/KinfuTsdfRequest.h>

typedef pcl::ScopeTime ScopeTimeT;

using pcl::gpu::kinfuLS::KinfuTracker;
using pcl::gpu::PtrStepSz;
using sensor_msgs::CameraInfo;
using sensor_msgs::Image;

typedef unsigned int uint;

///////////////////////////////////////////////////////////////////////////////////////////////////////////////////

struct SampledScopeTime : public pcl::StopWatch
{          
  enum { EACH = 33 };
  SampledScopeTime(int& time_ms) : time_ms_(time_ms) {}
  ~SampledScopeTime()
  {
    static int i_ = 0;
    time_ms_ += getTime();
    if (i_ % EACH == 0 && i_)
    {
      ROS_INFO("Avg frame time = %.2f ms (%.2f fps)",float(time_ms_) / EACH,float(1000.f * EACH / time_ms_));
      time_ms_ = 0;
    }
    ++i_;
  }
private:
  int& time_ms_;
};

///////////////////////////////////////////////////////////////////////////////////////////////////////////////////

class PosePublisher
{
  public:
  PosePublisher(ros::NodeHandle & nhandle)
  {
    m_reverse_initial_transformation = Eigen::Affine3f::Identity();
    m_initial_transformation = Eigen::Affine3f::Identity();						// added by DH
    nhandle.param<std::string>(PARAM_NAME_TF_REFERENCE_FRAME,m_first_frame_name,PARAM_DEFAULT_TF_REFERENCE_FRAME);
    nhandle.param<std::string>(PARAM_NAME_TF_CURRENT_FRAME,m_current_frame_name,PARAM_DEFAULT_TF_CURRENT_FRAME);
  }

  void publishPose(KinfuTracker& kinfu)
  {
    Eigen::Affine3f original_coords = m_reverse_initial_transformation * kinfu.getCameraPose();

    // after this, the z axis is the sensor axis and points forward
    // the x axis is horizontal (points right) and the y axis is vertical (points downward)
    Eigen::Matrix<float, 3, 3, Eigen::RowMajor> erreMats = original_coords.linear();
    Eigen::Vector3f teVecs = original_coords.translation();

    tf::Transform transform(
        tf::Matrix3x3(erreMats(0,0),erreMats(0, 1),erreMats(0, 2),
            erreMats(1,0),erreMats(1, 1),erreMats(1, 2),
            erreMats(2,0),erreMats(2, 1),erreMats(2, 2)),
        tf::Vector3(teVecs[0], teVecs[1], teVecs[2])
    );

    //m_transform = tf::StampedTransform(transform, ros::Time::now(), m_first_frame_name, m_current_frame_name);
		//m_tf_broadcaster.sendTransform(m_transform);

		//************** added by DH **************//
    Eigen::Vector3f teVecs2 = m_initial_transformation.translation();
		//tf::Transform transform2(tf::Quaternion(0,0,0,1), tf::Vector3(teVecs2[0], teVecs2[1], teVecs2[2]));
		tf::Transform transform2(tf::Quaternion(0,0,0,1), tf::Vector3(0, 0, 0));		

		m_transform_first2current = tf::StampedTransform(transform, ros::Time::now(), m_first_frame_name, m_current_frame_name);
		m_transform_link2first = tf::StampedTransform(transform2, ros::Time::now(), "kinect1_link", m_first_frame_name);
		m_tf_broadcaster.sendTransform(m_transform_first2current);
		m_tf_broadcaster.sendTransform(m_transform_link2first);
		//************** added by DH **************//
  }

  void setReverseInitialTransformation(Eigen::Affine3f it)
  {
    m_reverse_initial_transformation = it;
  }

	//************** added by DH **************//
  void setInitialTransformation(Eigen::Affine3f t)
  {
    m_initial_transformation = t;
  }
	//************** added by DH **************//

  std::string getFirstFrameName() const {return m_first_frame_name; }
  std::string getCurrentFrameName() const {return m_current_frame_name; }

  EIGEN_MAKE_ALIGNED_OPERATOR_NEW;

  private:
  // initial transformation applied, already inverted
  Eigen::Affine3f m_reverse_initial_transformation;
	Eigen::Affine3f m_initial_transformation;							// added by DH

  // for TF frames
  std::string m_first_frame_name;
  std::string m_current_frame_name;

  tf::TransformBroadcaster m_tf_broadcaster;

  //tf::StampedTransform m_transform;
	tf::StampedTransform m_transform_first2current;				// added by DH
	tf::StampedTransform m_transform_link2first;					// added by DH

  // forbid this constructor
  PosePublisher() {}
};

///////////////////////////////////////////////////////////////////////////////////////////////////////////////////

struct ImagePublisher
{
  ImagePublisher(ros::NodeHandle & nhandle)
  {
    image_transport::ImageTransport it(nhandle);
    nhandle.param<std::string>(PARAM_NAME_CURRENT_VIEW_TOPIC,m_current_view_topic,PARAM_DEFAULT_CURRENT_VIEW_TOPIC);
    m_view_publisher = it.advertise(m_current_view_topic, 10);
  }

  void
  publishScene (KinfuTracker& kinfu, const sensor_msgs::ImageConstPtr& depth)
  {
    kinfu.getImage (view_device_);

    int cols;
    view_device_.download (view_host_, cols);

    //convert image to sensor message
    m_msg = sensor_msgs::ImagePtr(new sensor_msgs::Image);
    sensor_msgs::fillImage((*m_msg), "rgb8", view_device_.rows(), view_device_.cols(),
            view_device_.cols() * 3, &view_host_[0]);

    m_msg->header.frame_id=depth->header.frame_id;
    m_view_publisher.publish(m_msg);
  }

  private:
  bool paint_image_;
  bool accumulate_views_;

  KinfuTracker::View view_device_;
  KinfuTracker::View colors_device_;
  std::vector<pcl::gpu::kinfuLS::PixelRGB> view_host_;

  std::string m_current_view_topic;

  //KinfuTracker::DepthMap generated_depth_;
  image_transport::Publisher m_view_publisher;

  sensor_msgs::ImagePtr m_msg;

  // forbid this constructor
  ImagePublisher() {}
};

///////////////////////////////////////////////////////////////////////////////////////////////////////////////////

class ICPIsLostPublisher
{
  public:
  ICPIsLostPublisher(ros::NodeHandle &nhandle)
  {
    nhandle.param<std::string>(PARAM_NAME_ICP_LOST_TOPIC,m_icp_lost_topic_name,PARAM_DEFAULT_ICP_LOST_TOPIC);
    m_icpIsLostPub = nhandle.advertise<std_msgs::Empty>(m_icp_lost_topic_name, 2);
  }

  void publishIcpIsLost()
  {
    m_icpIsLostPub.publish(std_msgs::Empty());
  }

  private:
  ros::Publisher m_icpIsLostPub;
  std::string m_icp_lost_topic_name;
};

///////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//************** added by DH **************//
class MeshPublisher
{
	public:
  MeshPublisher(ros::NodeHandle &nhandle)
  {		
		std::string m_mesh_topic_name;
		std::string m_current_frame_name;

    nhandle.param<std::string>(PARAM_NAME_MESH_TOPIC,m_mesh_topic_name,PARAM_DEFAULT_MESH_TOPIC);
    nhandle.param<std::string>(PARAM_NAME_TF_CURRENT_FRAME,m_current_frame_name,PARAM_DEFAULT_TF_CURRENT_FRAME);

		m_mesh_pub = nhandle.advertise<visualization_msgs::Marker>(m_mesh_topic_name, 1);

		m_meshes = visualization_msgs::Marker();
		m_meshes.header.frame_id = "kinect1_depth_optical_frame";
		m_meshes.ns = "kinect_mesh";
		m_meshes.id = 0;
		m_meshes.type = visualization_msgs::Marker().TRIANGLE_LIST;
		m_meshes.action = visualization_msgs::Marker().ADD;
		m_meshes.scale.x = 1;
		m_meshes.scale.y = 1;
		m_meshes.scale.z = 1;
		m_meshes.color.r = 1;
		m_meshes.color.g = 1;
		m_meshes.color.b = 1;
		m_meshes.color.a = 1;
		m_meshes.pose = geometry_msgs::Pose();
		m_meshes.pose.orientation.w = 1;
   }

  ~MeshPublisher(){}

	void publishMeshes(std::vector<Eigen::Vector3d> & triangles, Eigen::Vector3d box_center, bool silent)
	{
		m_meshes.points.clear();
		 	for(int i = 0; i < triangles.size(); i++){
				geometry_msgs::Point p;
				p.x = triangles[i].x()+box_center.x()-m_initial_transformation.translation().x();
				p.y = triangles[i].y()+box_center.y()-m_initial_transformation.translation().y();
	 			p.z = triangles[i].z()+box_center.z()-m_initial_transformation.translation().z();
				//std::cout << p.x << "\t" << p.y << "\t" << p.z << std::endl;
				m_meshes.points.push_back(p);
			}
		m_mesh_pub.publish(m_meshes);
		if (!silent) std::cout << m_meshes.points.size() << " points published" << std::endl;
	}
	
	void setInitialTransformation(Eigen::Affine3f t){
		m_initial_transformation = t;
	}

  private:
	ros::Publisher m_mesh_pub;
	visualization_msgs::Marker m_meshes;

	Eigen::Affine3f m_initial_transformation;
};
//************** added by DH **************//
///////////////////////////////////////////////////////////////////////////////////////////////////////////////////

class ResetSubscriber
{
  public:
  ResetSubscriber(ros::NodeHandle &nhandle,boost::mutex &shared_mutex,boost::condition_variable & cond):
    m_shared_mutex(shared_mutex),m_cond(cond)
  {
    nhandle.param<std::string>(PARAM_NAME_IN_RESET_TOPIC,m_req_topic_name,PARAM_DEFAULT_IN_RESET_TOPIC);
    m_subReq = nhandle.subscribe(m_req_topic_name, 1,&ResetSubscriber::resetCallback,this);

    m_reset_required = false;
  }

  void resetCallback(const std_msgs::Empty & /*msg*/)
  {
		printf("reset updated");
    boost::mutex::scoped_lock lock(m_shared_mutex);
    m_reset_required = true;
    m_cond.notify_one();
  }

  // WARNING: lock the shared mutex before calling this
  bool isResetRequired()
  {
    return m_reset_required;
  }

  // WARNING: lock the shared mutex before calling this
  void clearResetRequired()
  {
    m_reset_required = false;
  }

  private:
  ros::Subscriber m_subReq;
  std::string m_req_topic_name;
  bool m_reset_required;

  boost::mutex &m_shared_mutex;
  boost::condition_variable & m_cond;
};

///////////////////////////////////////////////////////////////////////////////////////////////////////////////////

class ImageSubscriber
{
  public:
  ImageSubscriber(ros::NodeHandle &nhandle,boost::mutex & shared_mutex,boost::condition_variable & cond): 
    m_shared_mutex(shared_mutex),m_cond(cond),m_nh(nhandle)
  {
    std::string prefix_topic;
    m_nh.param<std::string>(PARAM_NAME_PREFIX_TOPIC,prefix_topic,PARAM_DEFAULT_PREFIX_TOPIC);

    std::string depth_image_topic;
    m_nh.param<std::string>(PARAM_NAME_DEPTH_IMAGE_TOPIC,depth_image_topic,prefix_topic + PARAM_DEFAULT_DEPTH_IMAGE_TOPIC);

    std::string camera_info_topic;
    m_nh.param<std::string>(PARAM_NAME_CAMERA_INFO_TOPIC,camera_info_topic,prefix_topic + PARAM_DEFAULT_CAMERA_INFO_TOPIC);

    std::string image_topic;
    m_nh.param<std::string>(PARAM_NAME_IMAGE_TOPIC,image_topic,prefix_topic + PARAM_NAME_IMAGE_TOPIC);

    bool enable_texture_extraction = PARAM_DEFAULT_EXTRACT_TEXTURES;
    m_nh.getParam(PARAM_NAME_EXTRACT_TEXTURES,enable_texture_extraction);
    m_nh.getParam(PARAM_SNAME_EXTRACT_TEXTURES,enable_texture_extraction);

    // message_filters instead of image_transport because of synchronization over w-lan
    m_texture_sync = NULL;
    m_depth_only_sync = NULL;

    m_rgb_sub = NULL;
    m_depth_sub = NULL;
    m_info_sub = NULL;

    if (enable_texture_extraction)
    {
      m_depth_sub = new message_filters::Subscriber<Image>(m_nh, depth_image_topic, 2);
      m_info_sub  = new message_filters::Subscriber<CameraInfo>(m_nh, camera_info_topic, 2);
      m_rgb_sub   = new message_filters::Subscriber<Image>(m_nh, image_topic, 2);

      //the depth and the rgb cameras are not hardware synchronized
      //hence the depth and rgb images normally do not have the EXACT timestamp
      //so use approximate time policy for synchronization
      m_texture_sync = new message_filters::Synchronizer<DRGBSync>(DRGBSync(500), *m_depth_sub, *m_info_sub, *m_rgb_sub);
      m_texture_sync->registerCallback(boost::bind(&ImageSubscriber::imageCallback, this, _1, _2, _3));
      ROS_INFO("Running KinFu with texture extraction");
    }
    else
    {
      m_depth_sub = new message_filters::Subscriber<Image>(m_nh, depth_image_topic, 1);
      m_info_sub  = new message_filters::Subscriber<CameraInfo>(m_nh, camera_info_topic, 1);

      m_depth_only_sync = new message_filters::TimeSynchronizer<Image, CameraInfo>(*m_depth_sub, *m_info_sub, 500);
      m_depth_only_sync->registerCallback(boost::bind(&ImageSubscriber::imageCallback, this, _1, _2, sensor_msgs::ImageConstPtr()));
      ROS_INFO("Running KinFu without texture extraction");
    }

    m_has_image = false;
  }

  ~ImageSubscriber()
  {
    if (m_texture_sync)
      delete m_texture_sync;
    if (m_depth_only_sync)
      delete m_depth_only_sync;
    if (m_depth_sub)
      delete m_depth_sub;
    if (m_info_sub)
      delete m_info_sub;
    if (m_rgb_sub)
      delete m_rgb_sub;
  }

  void imageCallback(const sensor_msgs::ImageConstPtr& depth, const sensor_msgs::CameraInfoConstPtr& cameraInfo,
    const sensor_msgs::ImageConstPtr& rgb = sensor_msgs::ImageConstPtr())
  {
		//printf("image updated\n");
    boost::mutex::scoped_lock lock(m_shared_mutex);
    m_depth = depth;
    m_cameraInfo = cameraInfo;
    m_rgb = rgb;

    m_has_image = true;
    m_cond.notify_one();
  }

  // WARNING: lock the shared mutex before calling this
  bool hasImage()
  {
    return m_has_image;
  }

  // WARNING: lock the shared mutex before calling this
  void getImage(sensor_msgs::ImageConstPtr & depth,sensor_msgs::CameraInfoConstPtr & cameraInfo,sensor_msgs::ImageConstPtr & rgb)
  {
    if (!m_has_image)
      return;    

    depth = m_depth;
    cameraInfo = m_cameraInfo;
    rgb = m_rgb;
  }

  // WARNING: lock the shared mutex before calling this
  void clearImage()
  {
    m_has_image = false;
  }

  private:

  typedef message_filters::sync_policies::ApproximateTime<Image, CameraInfo, Image> DRGBSync;
  message_filters::Synchronizer<DRGBSync>* m_texture_sync;
  message_filters::TimeSynchronizer<Image, CameraInfo>* m_depth_only_sync;

  message_filters::Subscriber<Image>* m_rgb_sub;
  message_filters::Subscriber<Image>* m_depth_sub;
  message_filters::Subscriber<CameraInfo>* m_info_sub;

  sensor_msgs::ImageConstPtr m_rgb;
  sensor_msgs::ImageConstPtr m_depth;
  sensor_msgs::CameraInfoConstPtr m_cameraInfo;

  boost::mutex & m_shared_mutex;
  boost::condition_variable & m_cond;

  ros::NodeHandle & m_nh;

  bool m_has_image;
};

///////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//************** added by DH **************//
class PhantomSubscriber
{
  public:
  PhantomSubscriber(ros::NodeHandle &nhandle,tf::TransformListener & tlistener): 
    m_tf_listener(tlistener)
  {
		std::string m_phantom_joint_topic_name;
		std::string m_phantom_button1_topic_name;
		std::string m_phantom_button2_topic_name;	

		nhandle.param<std::string>(PARAM_NAME_PHANTOM_JOINT_TOPIC,m_phantom_joint_topic_name,PARAM_DEFAULT_PHANTOM_JOINT_TOPIC);
		nhandle.param<std::string>(PARAM_NAME_PHANTOM_BUTTON1_TOPIC,m_phantom_button1_topic_name,PARAM_DEFAULT_PHANTOM_BUTTON1_TOPIC);
		nhandle.param<std::string>(PARAM_NAME_PHANTOM_BUTTON2_TOPIC,m_phantom_button2_topic_name,PARAM_DEFAULT_PHANTOM_BUTTON2_TOPIC);

		m_joint_sub = nhandle.subscribe(m_phantom_joint_topic_name, 10, &PhantomSubscriber::jointCallback, this);
		m_button1_sub = nhandle.subscribe(m_phantom_button1_topic_name, 10, &PhantomSubscriber::button1Callback, this);
		m_button2_sub = nhandle.subscribe(m_phantom_button2_topic_name, 10, &PhantomSubscriber::button2Callback, this);

		m_joint_pose_phtm = geometry_msgs::Pose();
		m_joint_pose_phtm.orientation.w = 1.0;
		m_joint_pose_tsdf = geometry_msgs::Pose();
		m_joint_pose_tsdf.orientation.w = 1.0;

		m_button1 = false;
		m_button2 = false;

   }

  ~PhantomSubscriber(){}

  void jointCallback(const geometry_msgs::Pose::ConstPtr& msg)
  {
		//printf("joint updated (%f %f %f) \n", msg->position.x, msg->position.y, msg->position.z);
		m_joint_pose_phtm = geometry_msgs::Pose();
    m_joint_pose_phtm.position.x = msg->position.x;
		m_joint_pose_phtm.position.y = msg->position.y;
		m_joint_pose_phtm.position.z = msg->position.z;
		m_joint_pose_phtm.orientation.w = 1.0;
  }

  void button1Callback(const std_msgs::Bool::ConstPtr& msg)
  {
		//printf("button1 updated");
		m_button1 = msg->data;
  }

  void button2Callback(const std_msgs::Bool::ConstPtr& msg)
  {
		//printf("button2 updated");
		m_button2 = msg->data;
  }

  void getCursor(tf::Vector3 & cursor_tsdf)
  {
		ros::Time now = ros::Time::now();
    if(m_tf_listener.waitForTransform("kinect1_depth_optical_frame", "phantom", now,ros::Duration(0.1))){
		  tf::StampedTransform tf_phtm2kinect;		
			try{
			    m_tf_listener.lookupTransform("kinect1_depth_optical_frame", "phantom", now, tf_phtm2kinect);
			}
			catch(tf::TransformException ex){
			    ROS_ERROR("%s", ex.what());
			}
			tf::Vector3 cursor_phtm = tf::Vector3(m_joint_pose_phtm.position.x, m_joint_pose_phtm.position.y, m_joint_pose_phtm.position.z);
			tf::Vector3 cursor_kinect = tf_phtm2kinect(cursor_phtm);	
			Eigen::Vector3f trans = m_initial_transformation.translation();
			tf::Transform tf_kinect2tsdf(tf::Quaternion(0,0,0,1), tf::Vector3(trans.x(), trans.y(), trans.z()));
			cursor_tsdf = tf_kinect2tsdf(cursor_kinect);
			m_joint_pose_tsdf.position.x = cursor_tsdf.x();
			m_joint_pose_tsdf.position.y = cursor_tsdf.y();
			m_joint_pose_tsdf.position.z = cursor_tsdf.z();
			//printf("(%f, %f, %f)\n", cursor_kinect.x(), cursor_kinect.y(), cursor_kinect.z());		
		}
		else{
			std::cout<<"cannot find frame (" << "kinect1_depth_optical_frame" << ")" << std::endl;
			cursor_tsdf = tf::Vector3(m_joint_pose_tsdf.position.x, m_joint_pose_tsdf.position.y, m_joint_pose_tsdf.position.z);
		}		
  }

	void getBoxCenter(Eigen::Vector3d & box_center){
		box_center.x() = m_joint_pose_tsdf.position.x - m_initial_transformation.translation().x();
		box_center.y() = m_joint_pose_tsdf.position.y - m_initial_transformation.translation().y();
		box_center.z() = m_joint_pose_tsdf.position.z - m_initial_transformation.translation().z();	
	}

	void setInitialTransformation(Eigen::Affine3f t){
		m_initial_transformation = t;
	}

  private:
	ros::Subscriber m_joint_sub;
	ros::Subscriber m_button1_sub;
	ros::Subscriber m_button2_sub;

	tf::TransformListener & m_tf_listener;

	Eigen::Affine3f m_initial_transformation;

	geometry_msgs::Pose m_joint_pose_phtm;
	geometry_msgs::Pose m_joint_pose_tsdf;  
	bool m_button1, m_button2;	
};

///////////////////////////////////////////////////////////////////////////////////////////////////////////////////

class RobotSubscriber
{
  public:
  RobotSubscriber(ros::NodeHandle &nhandle,tf::TransformListener & tlistener): 
    m_tf_listener(tlistener)
  {
		
  }

  ~RobotSubscriber(){}

  void getRobotJoints(std::vector<Eigen::Vector3f> & robot_joints, geometry_msgs::Pose& kinect_pose)
  {
		ros::Time now = ros::Time::now();
		robot_joints.clear();
		
		// right_lower_elbow
    if(m_tf_listener.waitForTransform("kinect1_depth_optical_frame", "right_lower_elbow", now,ros::Duration(0.1))){
		  tf::StampedTransform tf_r_l_e;			// tf_right_lower_elbow		
			try{
			    m_tf_listener.lookupTransform("kinect1_depth_optical_frame", "right_lower_elbow", now, tf_r_l_e);
			}
			catch(tf::TransformException ex){
			    ROS_ERROR("%s", ex.what());
			}
			robot_joints.push_back(Eigen::Vector3f(tf_r_l_e.getOrigin().x(), 
																						tf_r_l_e.getOrigin().y(), 
																						tf_r_l_e.getOrigin().z()));
		}
		else{
			std::cout<<"cannot find frame (" << "right_lower_elbow" << ")" << std::endl;
			robot_joints.push_back(Eigen::Vector3f(0,0,0));
		}		
		
		// right_lower_forearm
    if(m_tf_listener.waitForTransform("kinect1_depth_optical_frame", "right_lower_forearm", now,ros::Duration(0.1))){
		  tf::StampedTransform tf_r_l_f;			// tf_right_lower_forearm		
			try{
			    m_tf_listener.lookupTransform("kinect1_depth_optical_frame", "right_lower_forearm", now, tf_r_l_f);
			}
			catch(tf::TransformException ex){
			    ROS_ERROR("%s", ex.what());
			}
			robot_joints.push_back(Eigen::Vector3f(tf_r_l_f.getOrigin().x(), 
																						tf_r_l_f.getOrigin().y(), 
																						tf_r_l_f.getOrigin().z()));
		}
		else{
			std::cout<<"cannot find frame (" << "right_lower_forearm" << ")" << std::endl;
			robot_joints.push_back(Eigen::Vector3f(0,0,0));
		}		
				
		// right_hand
    if(m_tf_listener.waitForTransform("kinect1_depth_optical_frame", "right_hand", now,ros::Duration(0.1))){
		  tf::StampedTransform tf_r_h;			// tf_right_hand	
			try{
			    m_tf_listener.lookupTransform("kinect1_depth_optical_frame", "right_hand", now, tf_r_h);
			}
			catch(tf::TransformException ex){
			    ROS_ERROR("%s", ex.what());
			}
			robot_joints.push_back(Eigen::Vector3f(tf_r_h.getOrigin().x(), 
																						tf_r_h.getOrigin().y(), 
																						tf_r_h.getOrigin().z()));
		}
		else{
			std::cout<<"cannot find frame (" << "right_hand" << ")" << std::endl;
			robot_joints.push_back(Eigen::Vector3f(0,0,0));
		}		

		kinect_pose.position.x = 0.145;
		kinect_pose.position.y = 0.042;
		kinect_pose.position.z = 0.970;

		kinect_pose.orientation.x = 0.013;
		kinect_pose.orientation.y = 0.273;
		kinect_pose.orientation.z = -0.056;
		kinect_pose.orientation.w = 0.960;		
  }

  private:
	tf::TransformListener & m_tf_listener;

};

//************** added by DH **************//
///////////////////////////////////////////////////////////////////////////////////////////////////////////////////

struct KinFuLSApp
{
  enum
  {
    PCD_BIN = 1, PCD_ASCII = 2, PLY = 3, MESH_PLY = 7, MESH_VTK = 8
  };
  KinFuLSApp(float vsz, float shiftDistance, ros::NodeHandle & nodeHandle, uint depth_height, uint depth_width) :
      scan_(false), scan_mesh_(false), scan_volume_(false), independent_camera_(false),
      registration_(false), integrate_colors_(false), pcd_source_(false), focal_length_(-1.f),
      m_reset_subscriber(nodeHandle,m_mutex,m_cond),
			m_image_subscriber(nodeHandle,m_mutex,m_cond),
      m_command_subscriber(nodeHandle,m_tf_listener,m_mutex,m_cond),
			m_phantom_subscriber(nodeHandle,m_tf_listener),								//added by DH
			m_robot_subscriber(nodeHandle,m_tf_listener),									//added by DH
			m_mesh_publisher(nodeHandle),																	//added by DH
      m_image_publisher(nodeHandle), 
			m_pose_publisher(nodeHandle), 						
			m_icp_is_lost_publisher(nodeHandle),
      m_world_download_manager(nodeHandle,m_mutex,m_cond),
      time_ms_(0), nh(nodeHandle)
  {
    //Init Kinfu Tracker
    Eigen::Vector3f volume_size = Eigen::Vector3f::Constant(vsz/*meters*/);

    ROS_INFO("--- CURRENT SETTINGS ---\n");
    ROS_INFO("Volume size is set to %.2f meters\n", vsz);
    ROS_INFO("Volume will shift when the camera target point is farther than %.2f meters from the volume center\n", shiftDistance);
    ROS_INFO("The target point is located at [0, 0, %.2f] in camera coordinates\n", 0.6*vsz);
    ROS_INFO("------------------------\n");

    // warning message if shifting distance is abnormally big compared to volume size
    if(shiftDistance > 2.5 * vsz)
      ROS_WARN("WARNING Shifting distance (%.2f) is very large compared to the volume size (%.2f).\nYou can modify it using --shifting_distance.\n", shiftDistance, vsz);

    kinfu_ = new pcl::gpu::kinfuLS::KinfuTracker(volume_size, shiftDistance, depth_height, depth_width);
    Eigen::Matrix3f R = Eigen::Matrix3f::Identity ();   // * AngleAxisf( pcl::deg2rad(-30.f), Vector3f::UnitX());
    Eigen::Vector3f t = volume_size * 0.5f - Eigen::Vector3f (0, 0, volume_size (2) / 2 * 1.2f);

    Eigen::Affine3f pose = Eigen::Translation3f (t) * Eigen::AngleAxisf (R);

    m_pose_publisher.setReverseInitialTransformation(pose.inverse());
		m_pose_publisher.setInitialTransformation(pose);										// added by DH
		m_mesh_publisher.setInitialTransformation(pose);										// added by DH
		m_phantom_subscriber.setInitialTransformation(pose);								// added by DH
    m_world_download_manager.setReverseInitialTransformation(pose.inverse());
    m_command_subscriber.setInitialTransformation(pose);
    m_world_download_manager.setReferenceFrameName(m_pose_publisher.getFirstFrameName());

    kinfu_->setInitialCameraPose(pose);
    kinfu_->volume().setTsdfTruncDist(0.030f/*meters*/);
    kinfu_->setIcpCorespFilteringParams(0.1f/*meters*/, sin(pcl::deg2rad(20.f)));
    //kinfu_->setDepthTruncationForICP(3.f/*meters*/);
    kinfu_->setCameraMovementThreshold(0.001f);

    //Init KinFuLSApp
    tsdf_cloud_ptr_ = pcl::PointCloud<pcl::PointXYZI>::Ptr(new pcl::PointCloud<pcl::PointXYZI>);

    frame_counter_ = 0;
    enable_texture_extraction_ = false;
    snapshot_rate_ = 45;

    m_request_termination = false;
  }

  ~KinFuLSApp()
  {
  }

  // this contains the main cycle for the kinfu thread
  void run()
  {
    boost::mutex::scoped_lock main_lock(m_mutex);

    while (!m_request_termination)
    {
      bool reset;
      std::string reset_command_id;
      bool hasimage;
      bool hasrequests;
      bool isrunning;
      bool istriggered;

      KinfuTracker::THint pose_hint;
      CommandSubscriber::Sphere::Ptr clear_sphere;
      CommandSubscriber::BBox::Ptr clear_bbox;

      while (!m_request_termination && 
        !(m_reset_subscriber.isResetRequired()) &&
        !(m_image_subscriber.hasImage()) &&
        !(m_world_download_manager.hasRequests()) &&
        !(m_command_subscriber.hasClearSphere()) &&
        !(m_command_subscriber.hasClearBBox()) &&
        !(m_command_subscriber.isTriggered()))
        m_cond.wait(main_lock);

      hasimage = m_image_subscriber.hasImage();
      hasrequests = m_world_download_manager.hasRequests();

      std::string istriggered_command_id;
      if ((istriggered = m_command_subscriber.isTriggered()))
        {
        istriggered_command_id = m_command_subscriber.getIsTriggeredCommandId();
        m_command_subscriber.clearTriggered();
        }

      reset = false;
      if (m_reset_subscriber.isResetRequired())
      {
        reset = true;
        m_reset_subscriber.clearResetRequired();
      }

      isrunning = m_command_subscriber.isRunning();

      // command execution is allowed only when a new image is available
      if (hasimage)
      {
        if (m_command_subscriber.isResetRequired())
        {
          reset = true;
          reset_command_id = m_command_subscriber.getResetCommandId();
          m_command_subscriber.clearResetRequired();
        }

        if (m_command_subscriber.hasHint())
        {
          pose_hint.type = m_command_subscriber.hasForcedHint() ?
            KinfuTracker::THint::HINT_TYPE_FORCED : KinfuTracker::THint::HINT_TYPE_HINT;
          pose_hint.transform = m_command_subscriber.getHintTransform();
          m_command_subscriber.clearHint();
        }

        pose_hint.ignore_minimum_movement = !m_command_subscriber.isEnabledMinimumMovement();
      }

      sensor_msgs::ImageConstPtr depth;
      sensor_msgs::CameraInfoConstPtr cameraInfo;
      sensor_msgs::ImageConstPtr rgb;
        
      if (hasimage)
      {
        m_image_subscriber.getImage(depth,cameraInfo,rgb);
        m_image_subscriber.clearImage();
      }

      clear_sphere = m_command_subscriber.getClearSphere();
      m_command_subscriber.clearClearSphere();

      clear_bbox = m_command_subscriber.getClearBBox();
      m_command_subscriber.clearClearBBox();

      // The information from ROS was copied, this may run along the main thread.
      main_lock.unlock();

      if (reset)
      {
        kinfu_->reset();
        m_command_subscriber.ack(reset_command_id,true);
        ROS_INFO("KinFu was reset.");
      }

      if (hasimage && (isrunning || istriggered))
        {
        execute(depth,cameraInfo,rgb,pose_hint);
        if (istriggered)
          m_command_subscriber.ack(istriggered_command_id,true);
        }

      if ((clear_sphere || clear_bbox || hasrequests) && !kinfu_->isShiftComplete())
      {
        ROS_INFO("kinfu: shift incomplete but requests pending, waiting for it...");
        ros::Rate rate(10);
        while (!kinfu_->isShiftComplete())
        {
          kinfu_->updateShift();
          rate.sleep();
        }
        ROS_INFO("kinfu: shift is now complete, can continue.");
      }

      if (clear_sphere)
      {
        kinfu_->clearSphere(clear_sphere->center,clear_sphere->radius);
        ROS_INFO("KinFu cleared sphere.");
        m_command_subscriber.ack(clear_sphere->command_id,true);
      }

      if (clear_bbox)
      {
        kinfu_->clearBBox(clear_bbox->min,clear_bbox->max);
        ROS_INFO("KinFu cleared bbox.");
        m_command_subscriber.ack(clear_bbox->command_id,true);
      }

      if (hasrequests)
        m_world_download_manager.respond(kinfu_);

      // lock the mutex again, it will be unlocked by the condition variable at the beginning of the cycle
      main_lock.lock();
    }
  }

  //callback function, called with every new depth topic message
  void execute(const sensor_msgs::ImageConstPtr& depth, const sensor_msgs::CameraInfoConstPtr& cameraInfo,
               const sensor_msgs::ImageConstPtr& rgb,const KinfuTracker::THint & pose_hint)
  {
    frame_counter_++;

    //if (kinfu_->icpIsLost())
    //{
    //  m_icp_is_lost_publisher.publishIcpIsLost();
    //  if (pose_hint.type == KinfuTracker::THint::HINT_TYPE_NONE)
    //    return;
    //}

    depth_device_.upload (&(depth->data[0]), depth->step, depth->height, depth->width);
     // if (integrate_colors_)
     //    image_view_.colors_device_.upload (rgb24.data, rgb24.step, rgb24.rows, rgb24.cols);


    /*
     *      [fx  0 cx]
     * K = 	[ 0 fy cy]
     * 		[ 0  0  1]
     */
    (*kinfu_).setDepthIntrinsics(cameraInfo->K[0], cameraInfo->K[4],
    		cameraInfo->K[2], cameraInfo->K[5]);


    float focal_length = (cameraInfo->K[0] + cameraInfo->K[4]) / 2;
    screenshot_manager_.setCameraIntrinsics(focal_length, cameraInfo->height, cameraInfo->width);

    
    SampledScopeTime fps(time_ms_);

		//************** added by DH **************//
		std::vector<Eigen::Vector3f> robot_joints;
		geometry_msgs::Pose kinect_pose;		
		m_robot_subscriber.getRobotJoints(robot_joints, kinect_pose);		
		//std::cout << "right_lower_elbow:(" << robot_joints[0].x() << " " << robot_joints[0].y() << " " << robot_joints[0].z() << endl;
		//std::cout << "right_lower_forearm:(" << robot_joints[1].x() << " " << robot_joints[1].y() << " " << robot_joints[1].z() << endl;
		//std::cout << "right_hand:(" << robot_joints[2].x() << " " << robot_joints[2].y() << " " << robot_joints[2].z() << endl;
		bool del_robot = true;
		for (int i = 0; i < 3; i++){
			del_robot = del_robot && robot_joints[i].x()!=0 && robot_joints[i].y()!=0 && robot_joints[i].z()!=0;
		}
		KinfuTracker::THint pose_hint_kinect;
		pose_hint_kinect.type = KinfuTracker::THint::HINT_TYPE_HINT;
		Eigen::Quaternionf Qtmp(kinect_pose.orientation.w, kinect_pose.orientation.x, kinect_pose.orientation.y, kinect_pose.orientation.z);
		Eigen::Matrix3f Qmat = Qtmp.toRotationMatrix();

		pose_hint_kinect.transform.translation()[0] = kinect_pose.position.x;
		pose_hint_kinect.transform.translation()[1] = kinect_pose.position.y;
		pose_hint_kinect.transform.translation()[2] = kinect_pose.position.z;
		
		//for (int i = 0; i < 3; i++){
		//	for (int j = 0; j < 3; 
		pose_hint_kinect.transform.linear() = Qmat;		

		if (del_robot) {
			(*kinfu_)(depth_device_, robot_joints, pose_hint);
			//else (*kinfu_)(depth_device_, pose_hint);
		  if (kinfu_->isFinished())
		    nh.shutdown();
		
			tf::Vector3 cursor;
			Eigen::Vector3d boxCenter;
			m_phantom_subscriber.getCursor(cursor);

		  boxCenter = kinfu_->extractBox(Eigen::Vector3f(cursor.getX(),cursor.getY(),cursor.getZ()));
			//std::vector<float> tsdfBox;																				
			//tsdfBox.clear();
			//kinfu_->volume_box().downloadTsdf(tsdfBox);	
		
			std::vector<Eigen::Vector3d> meshes;	
			m_world_download_manager.extractBoxMesh(kinfu_, meshes, true);
			m_mesh_publisher.publishMeshes(meshes, boxCenter, true);
			//usleep(500000);
			//************** added by DH **************//
		
		  m_image_publisher.publishScene(*kinfu_,depth);
		  m_pose_publisher.publishPose(*kinfu_);
		}


    //image_view_.publishGeneratedDepth(*kinfu_);
/*
    //save snapshots
    if (enable_texture_extraction_)
    {
      if (frame_counter_ % snapshot_rate_ == 0)
      {
        //convert sensor_msgs::Image to pcl::gpu::PixelRGB
        unsigned pixelCount = rgb->height * rgb->width;
        pcl::gpu::kinfuLS::PixelRGB * pixelRgbs = new pcl::gpu::kinfuLS::PixelRGB[pixelCount];
        for (unsigned i = 0; i < pixelCount; i++)
        {
          //the encoding given in the image is "bgr8"
          pixelRgbs[i].b = rgb->data[i * 3];
          pixelRgbs[i].g = rgb->data[i * 3 + 1];
          pixelRgbs[i].r = rgb->data[i * 3 + 2];
        }
        pcl::gpu::PtrStepSz<const pcl::gpu::kinfuLS::PixelRGB> rgb24(rgb->height, rgb->width, pixelRgbs, rgb->step);
        screenshot_manager_.saveImage(kinfu_->getCameraPose(), rgb24);
        delete[] pixelRgbs;
      }
    }*/
  }

  void start()
  {
    m_thread = boost::thread(&KinFuLSApp::run,this);
  }

  void prepareTermination()
  {
    boost::mutex::scoped_lock lock(m_mutex);
    m_request_termination = true;
    m_cond.notify_one();
  }

  void join()
  {
    prepareTermination();
    m_thread.join();
  }

  void setEnableTextureExtraction(bool e)
  {
    enable_texture_extraction_ = e;
  }

  bool isEnableTextureExtraction()
  {
    return enable_texture_extraction_;
  }

  void setExtractKnownPoints(bool e)
  {
    kinfu_->setExtractKnownPoints(e);
    if (e)
      kinfu_->setWeightCubeListener(m_world_download_manager.getWeightCubeListener());
  }

  void enableExtractBorderPoints()
  {
    TIncompletePointsListener::Ptr listener = m_world_download_manager.getIncompletePointsListener();
    listener->AddAcceptedType(TIncompletePointsListener::TYPE_BORDERS);
    kinfu_->setIncompletePointsListener(listener);
    ROS_INFO("kinfu: border points extraction enabled.");
  }

  void enableExtractFrontierPoints()
  {
    TIncompletePointsListener::Ptr listener = m_world_download_manager.getIncompletePointsListener();
    listener->AddAcceptedType(TIncompletePointsListener::TYPE_FRONTIERS);
    kinfu_->setIncompletePointsListener(listener);
    ROS_INFO("kinfu: frontier points extraction enabled.");
  }

  void setMarchingCubesVolumeSize(int size)
  {
    m_world_download_manager.setMarchingCubesVolumeSize(size);
  }

  void setSnapshotRate(int frame_count)
  {
    snapshot_rate_ = frame_count;
  }

  private:
  bool scan_;
  bool scan_mesh_;
  bool scan_volume_;

  bool independent_camera_;
  int frame_counter_;
  bool enable_texture_extraction_;

  bool registration_;
  bool integrate_colors_;
  bool pcd_source_;
  float focal_length_;

  KinfuTracker *kinfu_;

  ResetSubscriber m_reset_subscriber;
  ImageSubscriber m_image_subscriber;
  PhantomSubscriber m_phantom_subscriber;				// added by DH
  RobotSubscriber m_robot_subscriber;				// added by DH
  CommandSubscriber m_command_subscriber;

  ImagePublisher m_image_publisher;
  PosePublisher m_pose_publisher;	
  MeshPublisher m_mesh_publisher;								// added by DH
  ICPIsLostPublisher m_icp_is_lost_publisher;

  WorldDownloadManager m_world_download_manager;

  KinfuTracker::DepthMap depth_device_;

  pcl::PointCloud<pcl::PointXYZI>::Ptr tsdf_cloud_ptr_;

  boost::thread m_thread;
  bool m_request_termination;

  std::vector<pcl::gpu::kinfuLS::PixelRGB> source_image_data_;
  std::vector<unsigned short> source_depth_data_;
  PtrStepSz<const unsigned short> depth_;
  PtrStepSz<const pcl::gpu::kinfuLS::PixelRGB> rgb24_;

  int time_ms_;
  std::vector<pcl::gpu::kinfuLS::PixelRGB> view_host_;
  KinfuTracker::DepthMap generated_depth_;

  pcl::kinfuLS::ScreenshotManager screenshot_manager_;
  int snapshot_rate_;

  tf::TransformListener m_tf_listener;

  //the ros node handle used to shut down the node and stop capturing
  ros::NodeHandle & nh;

  boost::mutex m_mutex;
  boost::condition_variable m_cond;
};
///////////////////////////////////////////////////////////////////////////////////////////////////////////////////

int print_cli_help()
{
  cout << "\nKinFu parameters:" << endl;
  cout << "    --help, -h                        : print this message" << endl;
  cout << "\nkinfuLS node parameters:" << endl;
  cout << "    volume_size <in_meters>, vs       : define integration volume size" << endl;
  cout << "    shifting_distance <in_meters>, sd : define shifting threshold (distance target-point / cube center)"
      << endl;
  cout << "    snapshot_rate <X_frames>, sr      : Extract RGB textures every <X_frames>. Default: 45" << endl;
  cout << "    extract_textures, et              : extract RGB PNG images to KinFuSnapshots folder. Default: true"
      << endl;

  return 0;
}

///////////////////////////////////////////////////////////////////////////////////////////////////////////////////

int main(int argc, char* argv[])
{
	// check arguments
  if (pcl::console::find_switch(argc, argv, "--help") ||
    pcl::console::find_switch(argc, argv, "-h"))
    return print_cli_help();

  ros::init(argc, argv, "kinfuLS");
  ros::NodeHandle nh("~");
	//ros::NodeHandle nh;

  // assign value from parameter server, with default.
  int device;
  nh.param<int>(PARAM_NAME_CUDA_DEVICE_ID, device, PARAM_DEFAULT_CUDA_DEVICE_ID);
  pcl::gpu::setDevice(device);
  pcl::gpu::printShortCudaDeviceInfo(device);

  double volume_size = PARAM_DEFAULT_VOLUME_SIZE; //pcl::device::VOLUME_SIZE
  nh.getParam(PARAM_NAME_VOLUME_SIZE, volume_size);
  nh.getParam(PARAM_SNAME_VOLUME_SIZE, volume_size);

  double shift_distance = PARAM_DEFAULT_SHIFT_DISTANCE; //pcl::device::DISTANCE_THRESHOLD;
  nh.getParam(PARAM_NAME_SHIFT_DISTANCE, shift_distance);
  nh.getParam(PARAM_SNAME_SHIFT_DISTANCE, shift_distance);

  double depth_height = PARAM_DEFAULT_DEPTH_HEIGHT, depth_width = PARAM_DEFAULT_DEPTH_WIDTH;
  nh.getParam(PARAM_NAME_DEPTH_HEIGHT,depth_height);
  nh.getParam(PARAM_NAME_DEPTH_WIDTH,depth_width);

  KinFuLSApp app(volume_size, shift_distance, nh, depth_height, depth_width);

  int snapshot_rate = PARAM_DEFAULT_SNAPSHOT_RATE;
  nh.getParam(PARAM_NAME_SNAPSHOT_RATE, snapshot_rate);
  nh.getParam(PARAM_SNAME_SNAPSHOT_RATE, snapshot_rate);
  app.setSnapshotRate(snapshot_rate);

  bool enable_texture_extraction = PARAM_DEFAULT_EXTRACT_TEXTURES;
  nh.getParam(PARAM_NAME_EXTRACT_TEXTURES,enable_texture_extraction);
  nh.getParam(PARAM_SNAME_EXTRACT_TEXTURES,enable_texture_extraction);
  app.setEnableTextureExtraction(enable_texture_extraction);

  bool extract_known_points = PARAM_DEFAULT_EXTRACT_KNOWN_POINTS;
  nh.getParam(PARAM_NAME_EXTRACT_KNOWN_POINTS,extract_known_points);
  app.setExtractKnownPoints(extract_known_points);

  bool extract_border_points = PARAM_DEFAULT_EXTRACT_BORDER_POINTS;
  nh.getParam(PARAM_NAME_EXTRACT_BORDER_POINTS,extract_border_points);
  if (extract_border_points)
    app.enableExtractBorderPoints();

  bool extract_frontier_points = PARAM_DEFAULT_EXTRACT_FRONTIER_POINTS;
  nh.getParam(PARAM_NAME_EXTRACT_FRONTIER_POINTS,extract_frontier_points);
  if (extract_frontier_points)
    app.enableExtractFrontierPoints();

  int marching_cubes_volume_size = PARAM_DEFAULT_MARCHING_CUBE_SIZE;
  nh.getParam(PARAM_NAME_MARCHING_CUBE_SIZE,marching_cubes_volume_size);
  if (marching_cubes_volume_size > 0)
    app.setMarchingCubesVolumeSize(marching_cubes_volume_size);

  // start app main thread
  app.start();

  ros::spin();

  app.prepareTermination();
  app.join();

  return 0;
}
